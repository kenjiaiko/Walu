{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continued-volleyball",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cross-greeting",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "with open(\"access.log\") as f:\n",
    "    reader = csv.reader(f, delimiter=\" \")\n",
    "    for row in reader:\n",
    "        dataset.append(row)\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elder-seeking",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollow-russian",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_from_ip = {}\n",
    "for d in dataset:\n",
    "    dataset_from_ip.setdefault(d[0], [])\n",
    "    dataset_from_ip[d[0]].append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thorough-meaning",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset_from_ip.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mechanical-interface",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_ip80 = []\n",
    "for k in dataset_from_ip.keys():\n",
    "    for d in dataset_from_ip[k][:80]:\n",
    "        dataset_ip80.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "australian-concord",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset_ip80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naked-riverside",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chronic-sellers",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectors(dataset_ip80):\n",
    "    vectors = []\n",
    "    for d in dataset_ip80:\n",
    "        v, req = [], urllib.parse.unquote(d[5], \"utf-8\")\n",
    "        # find\n",
    "        v.append( req.find(\"%\") )\n",
    "        v.append( req.find(\":\") )\n",
    "        # count\n",
    "        v.append( req.count(\":\") )\n",
    "        v.append( req.count(\"(\") )\n",
    "        v.append( req.count(\";\") )\n",
    "        v.append( req.count(\"%\") )\n",
    "        v.append( req.count(\"/\") )\n",
    "        v.append( req.count(\"'\") )\n",
    "        v.append( req.count(\"<\") )\n",
    "        v.append( req.count(\"?\") )\n",
    "        v.append( req.count(\".\") )\n",
    "        v.append( req.count(\"#\") )\n",
    "        v.append( req.count(\"=\") )\n",
    "        v.append( req.count(\"\\\\\") )\n",
    "        v.append( req.count(\" \") )\n",
    "        # POST or NOT\n",
    "        v.append( 1 if req.find(\"POST\") == 0 else 0 )\n",
    "        # Count of non-alphabetic and non-numeric characters\n",
    "        f = [ c.isalnum() for c in req ]\n",
    "        v.append( f.count(False) )\n",
    "        # Count of non-alphabetic and non-numeric characters in path part\n",
    "        _pos = req.find(\" \")\n",
    "        v.append( f[_pos+1:].count(False) )\n",
    "        # Count of non-alphabetic and non-numeric characters in query part\n",
    "        _pos = req.find(\"?\")\n",
    "        v.append( f[_pos+1:].count(False) )\n",
    "        # Length of the most continuous non-alphabetic and non-numeric characters\n",
    "        _max, _cnt = 0, 0\n",
    "        for c in f:\n",
    "            if c == False:\n",
    "                _cnt += 1\n",
    "            else:\n",
    "                if _max < _cnt:\n",
    "                    _max = _cnt\n",
    "                _cnt = 0\n",
    "        if _max < _cnt:\n",
    "            _max = _cnt\n",
    "        v.append( _max )\n",
    "        # count 2bytes string\n",
    "        v.append( req.count(\"/%\") )\n",
    "        v.append( req.count(\"//\") )\n",
    "        v.append( req.count(\"/.\") )\n",
    "        v.append( req.count(\"..\") )\n",
    "        v.append( req.count(\"=/\") )\n",
    "        v.append( req.count(\"./\") )\n",
    "        v.append( req.count(\"/?\") )\n",
    "        vectors.append(v)\n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unable-cooler",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = get_vectors(dataset_ip80)\n",
    "len(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innocent-leather",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from sklearn.ensemble import IsolationForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boring-liberia",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "from sklearn import (manifold, datasets, decomposition, ensemble,\n",
    "                     discriminant_analysis, random_projection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "circular-discussion",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import pdist\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram, fcluster\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "physical-explosion",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _cluster_to_graph(X, th=1.0):\n",
    "    r = linkage(pdist((X)))\n",
    "    _v = sorted(r[:,2], reverse=True)\n",
    "    t = th * (sum(_v) / len(_v))\n",
    "    print(t)\n",
    "    c = fcluster(r, t, criterion=\"distance\")\n",
    "    count = {}\n",
    "    for i, v in enumerate(c):\n",
    "        count.setdefault(v, 0)\n",
    "        count[v] += 1\n",
    "    max_key = max(count.keys())\n",
    "    max_value = count[max_key]\n",
    "    del count[max_key]\n",
    "    for i in range(max_value):\n",
    "        count.setdefault(max_key, 1)\n",
    "        max_key += 1\n",
    "    _x = [ i for i in range(len(count.values())) ]\n",
    "    _y = sorted(count.values(), reverse=True)\n",
    "    return _x, _y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "human-screening",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _plot(_2d, _3d, _th=1.0, sz=600, title=\"\", target=None):\n",
    "    fig = make_subplots(rows=1, cols=3, \n",
    "                        specs=[[{\"type\": \"xy\"}, {\"type\": \"scene\"}, {}]])\n",
    "    if type(target) != type(None):\n",
    "        d, _text = {}, []\n",
    "        for i, t in enumerate(set(target)):\n",
    "            d.setdefault(t, i)\n",
    "        for t in target:\n",
    "            _text.append(int(d[t]))\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=_2d[:, 0], y=_2d[:, 1], \n",
    "                       mode='text', marker=dict(size=5), text=_text), \n",
    "            row=1, col=1)\n",
    "        fig.add_trace(\n",
    "            go.Scatter3d(x=_3d[:, 0], y=_3d[:, 1], z=_3d[:, 2], \n",
    "                         mode='text', marker=dict(size=1), text=_text),\n",
    "            row=1, col=2)\n",
    "    else:\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=_2d[:, 0], y=_2d[:, 1], \n",
    "                       mode='markers', marker=dict(size=5)), \n",
    "            row=1, col=1)\n",
    "        fig.add_trace(\n",
    "            go.Scatter3d(x=_3d[:, 0], y=_3d[:, 1], z=_3d[:, 2], \n",
    "                         mode='markers', marker=dict(size=1)),\n",
    "            row=1, col=2)\n",
    "    _left, _height = _cluster_to_graph(_3d, _th)\n",
    "    fig.add_trace(go.Bar(x=_left[:100], y=_height[:100], marker={}), row=1, col=3)\n",
    "    fig.update_layout(height=sz, width=sz*2, title_text=title, showlegend=False)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latin-option",
   "metadata": {},
   "source": [
    "# STEP 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signed-cemetery",
   "metadata": {},
   "outputs": [],
   "source": [
    "_x = np.array(vectors)\n",
    "clf = IsolationForest(random_state=0).fit(_x)\n",
    "_y = clf.predict(_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brilliant-bullet",
   "metadata": {},
   "outputs": [],
   "source": [
    "_idx = [ i for i in range(len(_x)) ]\n",
    "random.shuffle(_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "military-martin",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [ _x[i] for i in _idx[:10000] ]\n",
    "tsne = manifold.TSNE(n_components=2, init='pca', random_state=0)\n",
    "tsne3d = manifold.TSNE(n_components=3, init='pca', random_state=0)\n",
    "X_tsne = tsne.fit_transform(X)\n",
    "X_tsne3d = tsne3d.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mathematical-joshua",
   "metadata": {},
   "outputs": [],
   "source": [
    "_plot(X_tsne, X_tsne3d, 1.0, 400, \"Computing t-SNE embedding\", \n",
    "      [ _y[i] for i in _idx[:10000] ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "international-mounting",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "significant-bennett",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"IsolationForest01.pickle\", \"wb\") as f:\n",
    "    pickle.dump([dataset_ip80, _x, _y], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specialized-occurrence",
   "metadata": {},
   "source": [
    "# STEP 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "molecular-spending",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"IsolationForest01.pickle\", \"rb\") as f:\n",
    "    dataset_ip80, _x, _y = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appreciated-demonstration",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bottom-gibraltar",
   "metadata": {},
   "outputs": [],
   "source": [
    "len([ 1 for v in _y if v == -1 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "derived-calibration",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, vectors = [], []\n",
    "for i in range(len(_y)):\n",
    "    if _y[i] == -1:\n",
    "        dataset.append(dataset_ip80[i])\n",
    "        vectors.append(_x[i])\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overall-sewing",
   "metadata": {},
   "outputs": [],
   "source": [
    "_x = np.array(vectors)\n",
    "clf = IsolationForest(random_state=0).fit(_x)\n",
    "_y = clf.predict(_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loved-warning",
   "metadata": {},
   "outputs": [],
   "source": [
    "_idx = [ i for i in range(len(_x)) ]\n",
    "random.shuffle(_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cellular-wrapping",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [ _x[i] for i in _idx[:10000] ]\n",
    "tsne = manifold.TSNE(n_components=2, init='pca', random_state=0)\n",
    "tsne3d = manifold.TSNE(n_components=3, init='pca', random_state=0)\n",
    "X_tsne = tsne.fit_transform(X)\n",
    "X_tsne3d = tsne3d.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "living-identifier",
   "metadata": {},
   "outputs": [],
   "source": [
    "_plot(X_tsne, X_tsne3d, 1.0, 400, \"Computing t-SNE embedding\", \n",
    "      [ _y[i] for i in _idx[:10000] ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "knowing-ecology",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"IsolationForest02.pickle\", \"wb\") as f:\n",
    "    pickle.dump([dataset, _x, _y], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parental-effectiveness",
   "metadata": {},
   "source": [
    "# STEP 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "connected-motorcycle",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"IsolationForest02.pickle\", \"rb\") as f:\n",
    "    _dataset, _x, _y = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decimal-extent",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "random-company",
   "metadata": {},
   "outputs": [],
   "source": [
    "len([ 1 for v in _y if v == -1 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organizational-poison",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, vectors = [], []\n",
    "for i in range(len(_y)):\n",
    "    if _y[i] == -1:\n",
    "        dataset.append(_dataset[i])\n",
    "        vectors.append(_x[i])\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personal-perception",
   "metadata": {},
   "outputs": [],
   "source": [
    "_x = np.array(vectors)\n",
    "clf = IsolationForest(random_state=0).fit(_x)\n",
    "_y = clf.predict(_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effective-morocco",
   "metadata": {},
   "outputs": [],
   "source": [
    "_idx = [ i for i in range(len(_x)) ]\n",
    "random.shuffle(_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unavailable-discharge",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [ _x[i] for i in _idx[:10000] ]\n",
    "tsne = manifold.TSNE(n_components=2, init='pca', random_state=0)\n",
    "tsne3d = manifold.TSNE(n_components=3, init='pca', random_state=0)\n",
    "X_tsne = tsne.fit_transform(X)\n",
    "X_tsne3d = tsne3d.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ideal-squad",
   "metadata": {},
   "outputs": [],
   "source": [
    "_plot(X_tsne, X_tsne3d, 1.0, 400, \"Computing t-SNE embedding\", \n",
    "      [ _y[i] for i in _idx[:10000] ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "essential-theater",
   "metadata": {},
   "source": [
    "# STEP 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adopted-proxy",
   "metadata": {},
   "outputs": [],
   "source": [
    "_x = np.array(vectors)\n",
    "clf = IsolationForest(random_state=0).fit(_x)\n",
    "_y = clf.predict(_x)\n",
    "_yscore = clf.score_samples(_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convertible-double",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_from_ip = {}\n",
    "for i in range(len(dataset)):\n",
    "    if _y[i] != -1:\n",
    "        continue\n",
    "    dataset_from_ip.setdefault(dataset[i][0], [])\n",
    "    dataset_from_ip[dataset[i][0]].append([_yscore[i], dataset[i]])\n",
    "print_logs = []\n",
    "for k in dataset_from_ip.keys():\n",
    "    d = sorted(dataset_from_ip[k], key=lambda x:x[0])[0]\n",
    "    print_logs.append(d)\n",
    "len(print_logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "careful-broad",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"result_by_ip.txt\", \"w\") as f:\n",
    "    for d in sorted(print_logs, key=lambda x:x[0]):\n",
    "        f.write(str(d[0]) + \" \" + \" \".join(map(str, d[1])) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrapped-metadata",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
